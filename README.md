All info and details are in the [project description](https://saleemshahdi.github.io/Portfolio/ProjectDescriptions/Android/Android.html). Opening the link in another tab can be better for navigability.

The paragraph below is what we submitted as the readme to the project as per the project instructions:

We used models such as ChatGPT and deepseek to help us create xml files that were to our liking; rather than giving the models pictures, we chose to ask them for things like "can you create an xml file that will give a user an option to input an album name to choose to move a picture to," and we asked the mdoels to tweak where necessasry. We also used the models to help with debugging; being unfamiliar with android studio meant that we needed some help generating some code when our written code wouldn't work exactly as we had thought, becuase of errors with containers, etc. For instance, we used CHatgpt to help us generate code to extract URIs from the pictures and to get the pictures visible on the screen; without genAI, we would have been stuck.
